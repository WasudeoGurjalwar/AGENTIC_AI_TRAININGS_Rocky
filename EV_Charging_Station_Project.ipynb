{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WasudeoGurjalwar/AGENTIC_AI_TRAININGS_Rocky/blob/main/EV_Charging_Station_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "704de647"
      },
      "source": [
        "# Task\n",
        "Implement a multi-agent customer support workflow using LangGraph. The workflow should include a Classifier Agent to route queries (billing, technical, general) to specialized agents (Billing Agent, Technical Agent, General Agent). The final responses from the specialized agents should be aggregated into a single answer. Use Google Gemini (gemini-2.5-flash-lite) and OpenAI (gpt-4o-mini) models, initializing them in separate blocks after installing necessary libraries and configuring API keys."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78b570c3"
      },
      "source": [
        "## Install necessary libraries\n",
        "\n",
        "### Subtask:\n",
        "Install LangChain, LangGraph, and the libraries for interacting with Google Gemini and OpenAI APIs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "916f144b"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the necessary libraries using pip.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "669aa686",
        "outputId": "5e014d19-372d-448d-b66e-7b7ee6b6f7a2"
      },
      "source": [
        "%pip install --quiet langchain langgraph langchain-google-genai langchain-openai"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/155.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m153.6/155.4 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9f0aabb"
      },
      "source": [
        "## Configure api keys\n",
        "\n",
        "### Subtask:\n",
        "Add code to securely load and configure API keys for Google Gemini and OpenAI.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c46a1649"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to securely load and configure API keys for Google Gemini and OpenAI. This involves importing `getpass`, prompting the user for the keys, and setting them as environment variables. These steps can be done in a single code block.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93f6a28c"
      },
      "source": [
        "import getpass\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27fb4665"
      },
      "source": [
        "## Initialize language models\n",
        "\n",
        "### Subtask:\n",
        "Initialize two LLMs: one from Google (Gemini) and one from OpenAI (GPT).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75590384"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary classes and instantiate the Google Gemini and OpenAI GPT models as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db8ecc57"
      },
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "gemini_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\")\n",
        "openai_llm = ChatOpenAI(model=\"gpt-5-mini\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f687e02"
      },
      "source": [
        "## Define agent tools (optional but recommended)\n",
        "\n",
        "### Subtask:\n",
        "Although not explicitly requested, defining tools for each agent (e.g., knowledge base lookups, external API calls) will enhance their capabilities. This step will be marked as optional in the plan.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a34c238"
      },
      "source": [
        "**Reasoning**:\n",
        "Define placeholder functions for the tools that each agent might use.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efef3af6"
      },
      "source": [
        "def knowledge_base_lookup_tool(query: str) -> str:\n",
        "  \"\"\"Tool for searching a knowledge base for technical issues.\"\"\"\n",
        "  print(f\"Searching knowledge base for: {query}\")\n",
        "  # Placeholder implementation\n",
        "  return \"Information from knowledge base related to \" + query\n",
        "\n",
        "def billing_information_tool(customer_id: str) -> str:\n",
        "  \"\"\"Tool for accessing billing information.\"\"\"\n",
        "  print(f\"Accessing billing information for customer ID: {customer_id}\")\n",
        "  # Placeholder implementation\n",
        "  return \"Billing details for customer ID \" + customer_id\n",
        "\n",
        "def general_information_tool(query: str) -> str:\n",
        "  \"\"\"Tool for retrieving general information.\"\"\"\n",
        "  print(f\"Retrieving general information for: {query}\")\n",
        "  # Placeholder implementation\n",
        "  return \"General information about \" + query\n",
        "\n",
        "# The classifier agent might not need a specific tool beyond the LLM itself for routing.\n",
        "# However, if it needed to look up customer history to help with classification,\n",
        "# a tool could be defined here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f59d34f0"
      },
      "source": [
        "## Define agent nodes\n",
        "\n",
        "### Subtask:\n",
        "Create a node for each agent (Classifier, Billing, Technical, General). Each node will contain the logic for that agent.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3c32a3f"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the Python functions for each agent (Classifier, Billing, Technical, General) as described in the instructions, using the previously initialized language models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "335b9401"
      },
      "source": [
        "from langgraph.graph import StateGraph\n",
        "from typing import TypedDict, Annotated, Union\n",
        "import operator\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Define a state for the graph using TypedDict\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        query: initial customer query\n",
        "        classification: classification of the query\n",
        "        billing_response: str\n",
        "        technical_response: str\n",
        "        general_response: str\n",
        "        final_response: str\n",
        "    \"\"\"\n",
        "    query: str\n",
        "    classification: str\n",
        "    billing_response: str\n",
        "    technical_response: str\n",
        "    general_response: str\n",
        "    final_response: str\n",
        "\n",
        "# Redefine the classifier_agent to return a dictionary to update the state\n",
        "def classifier_agent(state: dict) -> dict:\n",
        "    \"\"\"Classifies the customer query and updates the state.\"\"\"\n",
        "    query = state['query']\n",
        "    print(f\"--- Classifier Agent Start ---\")\n",
        "    print(f\"Input Query: {query}\")\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a helpful assistant that classifies customer queries into one of the following categories: billing, technical, general. Respond with only the category name.\"),\n",
        "        (\"human\", \"Classify the following query: {query}\")\n",
        "    ])\n",
        "    chain = prompt | gemini_llm\n",
        "    category = chain.invoke({\"query\": query}).content.strip().lower() # Ensure clean output\n",
        "    # Basic parsing to extract the category\n",
        "    if \"billing\" in category:\n",
        "        classified_category = \"billing\"\n",
        "    elif \"technical\" in category:\n",
        "        classified_category = \"technical\"\n",
        "    else:\n",
        "        classified_category = \"general\"\n",
        "\n",
        "    print(f\"Classified as: {classified_category}\")\n",
        "    print(f\"Output State Update: {{'classification': '{classified_category}'}}\")\n",
        "    print(f\"--- Classifier Agent End ---\")\n",
        "\n",
        "    # Return a dictionary to update the state\n",
        "    return {\"classification\": classified_category}\n",
        "\n",
        "# Redefine the specialized agents to return dictionaries to update the state\n",
        "def billing_agent(state: dict) -> dict:\n",
        "    \"\"\"Handles billing queries and updates the state.\"\"\"\n",
        "    query = state['query']\n",
        "    print(f\"--- Billing Agent Start ---\")\n",
        "    print(f\"Input Query: {query}\")\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a helpful assistant that responds to billing queries.\"),\n",
        "        (\"human\", \"Respond to the following billing query: {query}\")\n",
        "    ])\n",
        "    chain = prompt | openai_llm\n",
        "    response = chain.invoke({\"query\": query}).content\n",
        "    print(f\"Response: {response}\")\n",
        "    print(f\"Output State Update: {{'billing_response': '{response}'}}\")\n",
        "    print(f\"--- Billing Agent End ---\")\n",
        "    return {\"billing_response\": response}\n",
        "\n",
        "def technical_agent(state: dict) -> dict:\n",
        "    \"\"\"Handles technical queries and updates the state.\"\"\"\n",
        "    query = state['query']\n",
        "    print(f\"--- Technical Agent Start ---\")\n",
        "    print(f\"Input Query: {query}\")\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a helpful assistant that responds to technical queries.\"),\n",
        "        (\"human\", \"Respond to the following technical query: {query}\")\n",
        "    ])\n",
        "    chain = prompt | openai_llm\n",
        "    response = chain.invoke({\"query\": query}).content\n",
        "    print(f\"Response: {response}\")\n",
        "    print(f\"Output State Update: {{'technical_response': '{response}'}}\")\n",
        "    print(f\"--- Technical Agent End ---\")\n",
        "    return {\"technical_response\": response}\n",
        "\n",
        "def general_agent(state: dict) -> dict:\n",
        "    \"\"\"Handles general queries and updates the state.\"\"\"\n",
        "    query = state['query']\n",
        "    print(f\"--- General Agent Start ---\")\n",
        "    print(f\"Input Query: {query}\")\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a helpful assistant that responds to general queries.\"),\n",
        "        (\"human\", \"Respond to the following general query: {query}\")\n",
        "    ])\n",
        "    chain = prompt | openai_llm\n",
        "    response = chain.invoke({\"query\": query}).content\n",
        "    print(f\"Response: {response}\")\n",
        "    print(f\"Output State Update: {{'general_response': '{response}'}}\")\n",
        "    print(f\"--- General Agent End ---\")\n",
        "    return {\"general_response\": response}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62f704a7"
      },
      "source": [
        "## Define router node\n",
        "\n",
        "### Subtask:\n",
        "Create a router node that takes the query and the output of the Classifier Agent to determine which Specialized Agent to route to.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d434b15"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the router function to direct the workflow based on the classifier's output.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2ae945b"
      },
      "source": [
        "def router(state: dict) -> str:\n",
        "    \"\"\"Routes the query based on the classifier's output.\"\"\"\n",
        "    classification = state.get('classification')\n",
        "    print(f\"--- Router Start ---\")\n",
        "    print(f\"Current state: {state}\")\n",
        "    print(f\"Received classification: {classification}\")\n",
        "\n",
        "    if classification == \"billing\":\n",
        "        next_node = \"billing_agent\"\n",
        "    elif classification == \"technical\":\n",
        "        next_node = \"technical_agent\"\n",
        "    else:\n",
        "        # Fallback to general agent for any other classification\n",
        "        next_node = \"general_agent\"\n",
        "\n",
        "    print(f\"Routing to: {next_node}\")\n",
        "    print(f\"--- Router End ---\")\n",
        "    return next_node"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7df834d4"
      },
      "source": [
        "## Define final response aggregator\n",
        "\n",
        "### Subtask:\n",
        "Create a node to collect the responses from the specialized agents and format them into a single response.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d742bcd9"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the `aggregate_response` function to collect responses from specialized agents and format them into a single string, then update the state and return it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b687c46"
      },
      "source": [
        "def aggregate_response(state: dict) -> dict:\n",
        "    \"\"\"Collects responses from specialized agents and formats a single response.\"\"\"\n",
        "    print(f\"--- Aggregation Node ---\")\n",
        "    print(f\"Current state before aggregation: {state}\")\n",
        "\n",
        "    billing_response = state.get('billing_response', \"\")\n",
        "    technical_response = state.get('technical_response', \"\")\n",
        "    general_response = state.get('general_response', \"\")\n",
        "\n",
        "    responses = []\n",
        "    if billing_response:\n",
        "        responses.append(f\"Billing Response: {billing_response}\")\n",
        "    if technical_response:\n",
        "        responses.append(f\"Technical Response: {technical_response}\")\n",
        "    if general_response:\n",
        "        responses.append(f\"General Response: {general_response}\")\n",
        "\n",
        "    final_response = \"\\n\".join(responses)\n",
        "    # Update the state with the final response.\n",
        "    # Ensure this is a dictionary update as expected by StateGraph.\n",
        "    update_dict = {'final_response': final_response}\n",
        "\n",
        "    print(f\"Aggregated Final Response: {final_response}\")\n",
        "    print(f\"Output State Update: {update_dict}\")\n",
        "    print(f\"------------------------\")\n",
        "    return update_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd49a1fc"
      },
      "source": [
        "## Build the langgraph workflow\n",
        "\n",
        "### Subtask:\n",
        "Connect the nodes using LangGraph to define the flow of the query through the system.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e63fd046"
      },
      "source": [
        "**Reasoning**:\n",
        "Connect the nodes using LangGraph to define the flow of the query through the system according to the instructions provided.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8L1g-gJ4itI"
      },
      "source": [
        "from langgraph.graph import StateGraph\n",
        "\n",
        "# Instantiate a StateGraph with the defined state\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Add the previously defined agent nodes and the router node\n",
        "workflow.add_node(\"classifier_agent\", classifier_agent)\n",
        "workflow.add_node(\"billing_agent\", billing_agent)\n",
        "workflow.add_node(\"technical_agent\", technical_agent)\n",
        "workflow.add_node(\"general_agent\", general_agent)\n",
        "workflow.add_node(\"router\", router)\n",
        "workflow.add_node(\"aggregate_response\", aggregate_response) # Add the aggregation node here\n",
        "\n",
        "# Set the entry point of the graph\n",
        "workflow.set_entry_point(\"classifier_agent\")\n",
        "\n",
        "# Add an edge from the classifier_agent to the router\n",
        "workflow.add_edge(\"classifier_agent\", \"router\")\n",
        "\n",
        "# Add conditional edges from the router to the specialized agent nodes\n",
        "# The router function's string output is used by add_conditional_edges to pick the next node\n",
        "workflow.add_conditional_edges(\n",
        "    \"router\",\n",
        "    router, # The router function determines the next node by returning its name (string)\n",
        "    {\n",
        "        \"billing_agent\": \"billing_agent\",\n",
        "        \"technical_agent\": \"technical_agent\",\n",
        "        \"general_agent\": \"general_agent\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# Add edges from each of the specialized agent nodes back to the aggregate_response node\n",
        "workflow.add_edge(\"billing_agent\", \"aggregate_response\")\n",
        "workflow.add_edge(\"technical_agent\", \"aggregate_response\")\n",
        "workflow.add_edge(\"general_agent\", \"aggregate_response\")\n",
        "\n",
        "\n",
        "# Set the aggregate_response node as the end point of the graph\n",
        "workflow.set_finish_point(\"aggregate_response\")\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40acf4a1"
      },
      "source": [
        "## Compile and run the workflow\n",
        "\n",
        "### Subtask:\n",
        "Compile the LangGraph workflow and test it with sample customer queries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36cdb57f"
      },
      "source": [
        "**Reasoning**:\n",
        "Define sample customer queries, iterate through them, and invoke the compiled LangGraph application for each query. Print the input query and the final response.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e30e3ff9"
      },
      "source": [
        "**Reasoning**:\n",
        "Review the code from the previous attempt to ensure the router returns a string and that add_conditional_edges is used correctly. Then, check if the agent nodes return dictionaries. Finally, re-compile the graph and test with sample queries while adding print statements for debugging the state updates.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "721cc284",
        "outputId": "e08bff07-04ef-4408-e35e-4f42167b1322"
      },
      "source": [
        "## FULL CODE IN THIS BLOCK\n",
        "\n",
        "from langgraph.graph import StateGraph\n",
        "from typing import TypedDict, Annotated, Union\n",
        "import operator\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Define a state for the graph using TypedDict\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        query: initial customer query\n",
        "        classification: classification of the query\n",
        "        billing_response: str\n",
        "        technical_response: str\n",
        "        general_response: str\n",
        "        final_response: str\n",
        "    \"\"\"\n",
        "    query: str\n",
        "    classification: str\n",
        "    billing_response: str\n",
        "    technical_response: str\n",
        "    general_response: str\n",
        "    final_response: str\n",
        "\n",
        "# Redefine the classifier_agent to return a dictionary to update the state\n",
        "def classifier_agent(state: dict) -> dict:\n",
        "    \"\"\"Classifies the customer query and updates the state.\"\"\"\n",
        "    query = state['query']\n",
        "    print(f\"--- Classifier Agent Start ---\")\n",
        "    print(f\"Input Query: {query}\")\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a helpful assistant that classifies customer queries into one of the following categories: billing, technical, general. Respond with only the category name.\"),\n",
        "        (\"human\", \"Classify the following query: {query}\")\n",
        "    ])\n",
        "    chain = prompt | openai_llm\n",
        "    category = chain.invoke({\"query\": query}).content.strip().lower() # Ensure clean output\n",
        "    # Basic parsing to extract the category\n",
        "    if \"billing\" in category:\n",
        "        classified_category = \"billing\"\n",
        "    elif \"technical\" in category:\n",
        "        classified_category = \"technical\"\n",
        "    else:\n",
        "        classified_category = \"general\"\n",
        "\n",
        "    print(f\"Classified as: {classified_category}\")\n",
        "    print(f\"Output State Update: {{'classification': '{classified_category}'}}\")\n",
        "    print(f\"--- Classifier Agent End ---\")\n",
        "\n",
        "    # Return a dictionary to update the state\n",
        "    return {\"classification\": classified_category}\n",
        "\n",
        "# Redefine the specialized agents to return dictionaries to update the state\n",
        "def billing_agent(state: dict) -> dict:\n",
        "    \"\"\"Handles billing queries and updates the state.\"\"\"\n",
        "    query = state['query']\n",
        "    print(f\"--- Billing Agent Start ---\")\n",
        "    print(f\"Input Query: {query}\")\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a helpful assistant that responds to billing queries.\"),\n",
        "        (\"human\", \"Respond to the following billing query: {query}\")\n",
        "    ])\n",
        "    chain = prompt | openai_llm\n",
        "    response = chain.invoke({\"query\": query}).content\n",
        "    print(f\"Response: {response}\")\n",
        "    print(f\"Output State Update: {{'billing_response': '{response}'}}\")\n",
        "    print(f\"--- Billing Agent End ---\")\n",
        "    return {\"billing_response\": response}\n",
        "\n",
        "def technical_agent(state: dict) -> dict:\n",
        "    \"\"\"Handles technical queries and updates the state.\"\"\"\n",
        "    query = state['query']\n",
        "    print(f\"--- Technical Agent Start ---\")\n",
        "    print(f\"Input Query: {query}\")\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a helpful assistant that responds to technical queries.\"),\n",
        "        (\"human\", \"Respond to the following technical query: {query}\")\n",
        "    ])\n",
        "    chain = prompt | openai_llm\n",
        "    response = chain.invoke({\"query\": query}).content\n",
        "    print(f\"Response: {response}\")\n",
        "    print(f\"Output State Update: {{'technical_response': '{response}'}}\")\n",
        "    print(f\"--- Technical Agent End ---\")\n",
        "    return {\"technical_response\": response}\n",
        "\n",
        "def general_agent(state: dict) -> dict:\n",
        "    \"\"\"Handles general queries and updates the state.\"\"\"\n",
        "    query = state['query']\n",
        "    print(f\"--- General Agent Start ---\")\n",
        "    print(f\"Input Query: {query}\")\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a helpful assistant that responds to general queries.\"),\n",
        "        (\"human\", \"Respond to the following general query: {query}\")\n",
        "    ])\n",
        "    chain = prompt | openai_llm\n",
        "    response = chain.invoke({\"query\": query}).content\n",
        "    print(f\"Response: {response}\")\n",
        "    print(f\"Output State Update: {{'general_response': '{response}'}}\")\n",
        "    print(f\"--- General Agent End ---\")\n",
        "    return {\"general_response\": response}\n",
        "\n",
        "# Redefine the router node\n",
        "def router(state: dict) -> str:\n",
        "    \"\"\"Routes the query based on the classifier's output.\"\"\"\n",
        "    classification = state.get('classification')\n",
        "    print(f\"--- Router Start ---\")\n",
        "    print(f\"Current state: {state}\")\n",
        "    print(f\"Received classification: {classification}\")\n",
        "\n",
        "    if classification == \"billing\":\n",
        "        next_node = \"billing_agent\"\n",
        "    elif classification == \"technical\":\n",
        "        next_node = \"technical_agent\"\n",
        "    else:\n",
        "        # Fallback to general agent for any other classification\n",
        "        next_node = \"general_agent\"\n",
        "\n",
        "    print(f\"Routing to: {next_node}\")\n",
        "    print(f\"--- Router End ---\")\n",
        "    return next_node\n",
        "\n",
        "# Redefine the aggregate_response node\n",
        "def aggregate_response(state: dict) -> dict:\n",
        "    \"\"\"Collects responses from specialized agents and formats a single response.\"\"\"\n",
        "    print(f\"--- Aggregation Node ---\")\n",
        "    print(f\"Current state before aggregation: {state}\")\n",
        "\n",
        "    billing_response = state.get('billing_response', \"\")\n",
        "    technical_response = state.get('technical_response', \"\")\n",
        "    general_response = state.get('general_response', \"\")\n",
        "\n",
        "    responses = []\n",
        "    if billing_response:\n",
        "        responses.append(f\"Billing Response: {billing_response}\")\n",
        "    if technical_response:\n",
        "        responses.append(f\"Technical Response: {technical_response}\")\n",
        "    if general_response:\n",
        "        responses.append(f\"General Response: {general_response}\")\n",
        "\n",
        "    final_response = \"\\n\".join(responses)\n",
        "    # Update the state with the final response.\n",
        "    # Ensure this is a dictionary update as expected by StateGraph.\n",
        "    update_dict = {'final_response': final_response}\n",
        "\n",
        "    print(f\"Aggregated Final Response: {final_response}\")\n",
        "    print(f\"Output State Update: {update_dict}\")\n",
        "    print(f\"------------------------\")\n",
        "    return update_dict\n",
        "\n",
        "\n",
        "# Re-compile the graph with the updated nodes\n",
        "# Instantiate a StateGraph with the defined state\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Add the updated agent nodes and the router node\n",
        "workflow.add_node(\"classifier_agent\", classifier_agent)\n",
        "workflow.add_node(\"billing_agent\", billing_agent)\n",
        "workflow.add_node(\"technical_agent\", technical_agent)\n",
        "workflow.add_node(\"general_agent\", general_agent)\n",
        "workflow.add_node(\"router\", router)\n",
        "workflow.add_node(\"aggregate_response\", aggregate_response)\n",
        "\n",
        "\n",
        "# Set the entry point of the graph\n",
        "workflow.set_entry_point(\"classifier_agent\")\n",
        "# workflow.add_edge(\"classifier_agent\", \"router\")\n",
        "\n",
        "# Instead, use add_conditional_edges from classifier_agent:\n",
        "workflow.add_conditional_edges(\n",
        "    \"classifier_agent\",  # source node\n",
        "    router,              # routing function\n",
        "    {\n",
        "        \"billing_agent\": \"billing_agent\",\n",
        "        \"technical_agent\": \"technical_agent\",\n",
        "        \"general_agent\": \"general_agent\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# REMOVE explicit edges from specialized agents to aggregate_response\n",
        "# workflow.add_edge(\"billing_agent\", \"aggregate_response\")\n",
        "# workflow.add_edge(\"technical_agent\", \"aggregate_response\")\n",
        "# workflow.add_edge(\"general_agent\", \"aggregate_response\")\n",
        "\n",
        "# Set the aggregate_response node as the end point of the graph\n",
        "# We will now add edges from the specialized agents to the aggregate_response node\n",
        "workflow.add_edge(\"billing_agent\", \"aggregate_response\")\n",
        "workflow.add_edge(\"technical_agent\", \"aggregate_response\")\n",
        "workflow.add_edge(\"general_agent\", \"aggregate_response\")\n",
        "\n",
        "workflow.set_finish_point(\"aggregate_response\")\n",
        "\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "# Define sample customer queries\n",
        "sample_queries = [\n",
        "    \"What is my current bill amount?\",  # Billing query\n",
        "    #\"My internet connection is slow, how can I fix it?\", # Technical query\n",
        "    #\"What are your operating hours?\", # General query\n",
        "    #\"How do I update my payment information?\" # Billing query\n",
        "]\n",
        "\n",
        "# Iterate through sample queries and test the workflow\n",
        "for query in sample_queries:\n",
        "    print(f\"=== Running workflow for query: {query} ===\")\n",
        "    # Invoke the compiled LangGraph application\n",
        "    # The initial state should contain the input query\n",
        "    result = app.invoke({\"query\": query})\n",
        "    # The final response is stored in the 'final_response' key of the final state\n",
        "    print(f\"--- Final Result ---\")\n",
        "    print(f\"Input Query: {query}\")\n",
        "    print(f\"Final Response: {result.get('final_response', 'No final response generated.')}\")\n",
        "    print(f\"===========================================\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Running workflow for query: What is my current bill amount? ===\n",
            "--- Classifier Agent Start ---\n",
            "Input Query: What is my current bill amount?\n",
            "Classified as: billing\n",
            "Output State Update: {'classification': 'billing'}\n",
            "--- Classifier Agent End ---\n",
            "--- Router Start ---\n",
            "Current state: {'classification': 'billing', 'query': 'What is my current bill amount?'}\n",
            "Received classification: billing\n",
            "Routing to: billing_agent\n",
            "--- Router End ---\n",
            "--- Billing Agent Start ---\n",
            "Input Query: What is my current bill amount?\n",
            "Response: I don’t have access to your account, so I can’t look up your bill directly. I can help you find it — which account or provider is this for (electric, water, phone, cable, etc.)?\n",
            "\n",
            "Ways to check your current bill now:\n",
            "- Online: Sign in to your provider’s website or mobile app → Account/Billing → Current balance or Statements.  \n",
            "- Email: Check the most recent billing email from the provider (subject often includes “Your bill” or “Statement”).  \n",
            "- Paper: Look at the most recent mailed statement for “Current amount due” and due date.  \n",
            "- Phone: Call the provider’s customer service or automated billing line (have your account number ready).  \n",
            "- Text/Chat: Some providers offer SMS or live chat billing inquiry when signed in.\n",
            "\n",
            "If you want, tell me the provider and whether you prefer web or phone instructions and I’ll walk you through the exact steps. Don’t post account numbers, passwords, SSNs, or other sensitive info here — if you need me to perform an account-specific lookup, use your provider’s secure support channel.\n",
            "Output State Update: {'billing_response': 'I don’t have access to your account, so I can’t look up your bill directly. I can help you find it — which account or provider is this for (electric, water, phone, cable, etc.)?\n",
            "\n",
            "Ways to check your current bill now:\n",
            "- Online: Sign in to your provider’s website or mobile app → Account/Billing → Current balance or Statements.  \n",
            "- Email: Check the most recent billing email from the provider (subject often includes “Your bill” or “Statement”).  \n",
            "- Paper: Look at the most recent mailed statement for “Current amount due” and due date.  \n",
            "- Phone: Call the provider’s customer service or automated billing line (have your account number ready).  \n",
            "- Text/Chat: Some providers offer SMS or live chat billing inquiry when signed in.\n",
            "\n",
            "If you want, tell me the provider and whether you prefer web or phone instructions and I’ll walk you through the exact steps. Don’t post account numbers, passwords, SSNs, or other sensitive info here — if you need me to perform an account-specific lookup, use your provider’s secure support channel.'}\n",
            "--- Billing Agent End ---\n",
            "--- Aggregation Node ---\n",
            "Current state before aggregation: {'query': 'What is my current bill amount?', 'classification': 'billing', 'billing_response': 'I don’t have access to your account, so I can’t look up your bill directly. I can help you find it — which account or provider is this for (electric, water, phone, cable, etc.)?\\n\\nWays to check your current bill now:\\n- Online: Sign in to your provider’s website or mobile app → Account/Billing → Current balance or Statements.  \\n- Email: Check the most recent billing email from the provider (subject often includes “Your bill” or “Statement”).  \\n- Paper: Look at the most recent mailed statement for “Current amount due” and due date.  \\n- Phone: Call the provider’s customer service or automated billing line (have your account number ready).  \\n- Text/Chat: Some providers offer SMS or live chat billing inquiry when signed in.\\n\\nIf you want, tell me the provider and whether you prefer web or phone instructions and I’ll walk you through the exact steps. Don’t post account numbers, passwords, SSNs, or other sensitive info here — if you need me to perform an account-specific lookup, use your provider’s secure support channel.'}\n",
            "Aggregated Final Response: Billing Response: I don’t have access to your account, so I can’t look up your bill directly. I can help you find it — which account or provider is this for (electric, water, phone, cable, etc.)?\n",
            "\n",
            "Ways to check your current bill now:\n",
            "- Online: Sign in to your provider’s website or mobile app → Account/Billing → Current balance or Statements.  \n",
            "- Email: Check the most recent billing email from the provider (subject often includes “Your bill” or “Statement”).  \n",
            "- Paper: Look at the most recent mailed statement for “Current amount due” and due date.  \n",
            "- Phone: Call the provider’s customer service or automated billing line (have your account number ready).  \n",
            "- Text/Chat: Some providers offer SMS or live chat billing inquiry when signed in.\n",
            "\n",
            "If you want, tell me the provider and whether you prefer web or phone instructions and I’ll walk you through the exact steps. Don’t post account numbers, passwords, SSNs, or other sensitive info here — if you need me to perform an account-specific lookup, use your provider’s secure support channel.\n",
            "Output State Update: {'final_response': 'Billing Response: I don’t have access to your account, so I can’t look up your bill directly. I can help you find it — which account or provider is this for (electric, water, phone, cable, etc.)?\\n\\nWays to check your current bill now:\\n- Online: Sign in to your provider’s website or mobile app → Account/Billing → Current balance or Statements.  \\n- Email: Check the most recent billing email from the provider (subject often includes “Your bill” or “Statement”).  \\n- Paper: Look at the most recent mailed statement for “Current amount due” and due date.  \\n- Phone: Call the provider’s customer service or automated billing line (have your account number ready).  \\n- Text/Chat: Some providers offer SMS or live chat billing inquiry when signed in.\\n\\nIf you want, tell me the provider and whether you prefer web or phone instructions and I’ll walk you through the exact steps. Don’t post account numbers, passwords, SSNs, or other sensitive info here — if you need me to perform an account-specific lookup, use your provider’s secure support channel.'}\n",
            "------------------------\n",
            "--- Final Result ---\n",
            "Input Query: What is my current bill amount?\n",
            "Final Response: Billing Response: I don’t have access to your account, so I can’t look up your bill directly. I can help you find it — which account or provider is this for (electric, water, phone, cable, etc.)?\n",
            "\n",
            "Ways to check your current bill now:\n",
            "- Online: Sign in to your provider’s website or mobile app → Account/Billing → Current balance or Statements.  \n",
            "- Email: Check the most recent billing email from the provider (subject often includes “Your bill” or “Statement”).  \n",
            "- Paper: Look at the most recent mailed statement for “Current amount due” and due date.  \n",
            "- Phone: Call the provider’s customer service or automated billing line (have your account number ready).  \n",
            "- Text/Chat: Some providers offer SMS or live chat billing inquiry when signed in.\n",
            "\n",
            "If you want, tell me the provider and whether you prefer web or phone instructions and I’ll walk you through the exact steps. Don’t post account numbers, passwords, SSNs, or other sensitive info here — if you need me to perform an account-specific lookup, use your provider’s secure support channel.\n",
            "===========================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "32s5cGc3EibQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}